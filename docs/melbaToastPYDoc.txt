Documentation of melbaToast.py

-  -  -
Installation:
Python 3.10 strongly reccommended.

Requirements:
 .llama-cpp-python
 .chromadb
 .nrclex

All requirements are available to be downloaded with pip.

Models require to be converted into the GGUF-V3 file format.
Supported models:
 .OpenHermes-Mistral(All versions)
 .Pygmalion(1&2)
 .OpenChat
 .Zephyr
 .Alpaca

After installing every requirement, organize your workspace
and initialize the memory database via the `initMemoryDB.py`
script.
-  -  -

def __init__(self, modelPath, databaseapath, logPath)
Parameters: 
	modelPath: string
	- Specifies where the .gguf model file is located. Must be a valid file
	  path
	logPath: string
	- Specifies a path where all logs are being saved to, logs are also shown
	  on the console after being saved.
Functionality:
	Initializes the general config class with default parameters that should
	provide immediate usability for most uses cases.
	Further sets the modelPath variable inside the configuration class equal
	to parameter [modelPath].
	At last the LLM itself is initialized with the initial configuration class
	and the database is loaded into memory.
Usage:
	llm = Melba(modelPath, systemPromptPath, databasePath)



def defaultConfig(self)
Parameters: None
Functionality:
	Returns a default object of the LLMConfig class and applies parameters that
	have proven to result in good responses.
Usage:
	cfg: LLMConfig = LLMUtils.LLMConfig()



def getCurrentConfig(self)
Parameters: None
Functionality:
	Returns the currently used LLMConfig object.
Usage:
	cfg: LLMConfig = Melba.getCurrentConfig()



def updateLLMConfig(self, newConfig)
Parameters: 
	newConfig: LLMConfig
	- Takes a LLMConfig class object as it's parameter
Functionality:
	Updates the parameters variable currently in use by the llm.
Usage:
	Melba.updateLLMConfig(LLMConfig)



def getMelbaResponse(self, message, person)
Parameters:
	message: string
	- Message the LLM will generate a response to.
	person: string
	- Can be any type of name, Twitch username, Discord username...

Functionality:
	Builds the final prompt by querying a database for past memories
	of the person/viewer [person] should there be any, otherwise a generic
	prompt type is used. Returns Melba's response as a string.
	Note: Response streaming is disabled for now
Usage:
	response = Melba.getMelbaResponse("Hi!", "placeholder")
